# rmw-utf8 - kompresné kódovanie utf8

Krátky algoritmus kompresie textu utf-8 optimalizovaný pre čínštinu, založený na programovacom jazyku rust.

Poznámka: rmw-utf8 dokáže komprimovať iba text utf-8, nie je to všeobecný algoritmus binárnej kompresie.

Existuje [verzia rust](https://github.com/rmw-link/rmw-utf8) a [verzia wasm](https://github.com/rmw-lib/rmw-utf8-wasm) pre javascript.

## Ako používať

```rust
use rmw_utf8::{decode, encode};

fn main() {
  let txt = "测试一下";
  let compressed = encode(&txt.as_bytes());
  let decompressed = decode(&compressed[..]);
  assert!(txt == decompressed);
}
```

## Hodnotenie miery kompresie

Tento algoritmus je určený na kompresiu krátkych textov a jeho výsledky sú nasledovné. Ako vidíte, čím kratší je text, tým lepšia je miera kompresie tohto algoritmu.

Pri 22467 bajtoch (približne 7500 čínskych znakov) rmw-utf8 stále prekonáva všeobecné kompresné algoritmy.

```
#include compress_test/test.txt
```

Testovací počítač je MacBook Pro 2015 ( 2,2 GHz Intel Core i7 )

Testovací kód nájdete na adrese [compress_test](https://github.com/rmw-link/rmw-utf8/tree/master/compress_test)

## Poznámky k používaniu

Kompresia nahrádza v texte `\r\n` aj `\r` pomocou `\n`, čo znamená, že komprimovaný a dekomprimovaný text nemusia byť identické.

### História

`\r``\n` Prvý z nich presunie kurzor na začiatok riadku a druhý presunie kurzor o jeden snímok nižšie.

Kedysi dávno pred počítačmi existoval stroj s názvom Teletype Model, ktorý dokázal napísať 10 znakov za sekundu.

Problémom bolo, že vytvorenie zlomu riadku trvalo 0,2 sekundy. Ak by v priebehu 0,2 sekundy prišla nová postava, postava by sa stratila.

Vývojári preto prišli s nápadom pridať na každý riadok dva znaky konca riadku.

Jeden z nich sa nazýva "carriage return" (návrat vozíka), ktorý hovorí písaciemu stroju, aby umiestnil tlačovú hlavu na ľavý okraj, a druhý sa nazýva "line feed" (posun riadku), ktorý hovorí písaciemu stroju, aby posunul papier o jeden riadok nižšie.

Odtiaľto pochádzajú "line feed" a "carriage return".

Neskôr, keď bol vynájdený počítač, boli tieto dva pojmy aplikované aj na počítače. V tom čase bola pamäť veľmi drahá a niektorí vedci si mysleli, že pridávať dva znaky na koniec každého riadku je príliš neekonomické, takže stačil jeden.

Svet sa otvoril.

V systémoch Unix/Linux je jediným znakom na konci každého riadku "line feed", `\n`; v systémoch Windows je predvoleným znakom "carriage return + line feed", `\r\n`; v systémoch Mac je predvoleným znakom "carriage return " alebo `\r`.

Moderné textové editory už podporujú `\n` ako ukončovací znak, takže nie je potrebné používať `\r`.

## Školenie vlastných slovníkov

Na zvýšenie účinku kompresie je možné vycvičiť vlastnú sadu kompresných slovníkov pre rôzne jazyky a typy textu.

```bash
git clone --depth=1 https://github.com/rmw-link/rmw-utf8.git
cd rmw-utf8
# 在txt目录下放你的准备训练语料，格式为utf8编码的txt文件
cd train
./train.sh
```

## Kompresia streamovania ešte nie je implementovaná

Nebola vykonaná žiadna kompresia prúdového prenosu (koniec koncov, môj scenár sa týka hlavne krátkych textov).

Každý, kto to potrebuje, si môže sám zabaliť ďalšiu kompresiu streamovania.

Napríklad komprimujte každý 1 MB a potom zaznamenajte počet bajtov komprimovaného obsahu na začiatku každého odseku po kompresii.

## Zásady kódovania

Text s desiatkami až niekoľkými stovkami znakov, najmä v čínštine, nie je vhodný pre všeobecné kompresné algoritmy.

Napríklad som testoval [zstd](https://github.com/facebook/zstd), najvýkonnejší kompresný algoritmus na svete, a ten často komprimoval 42 bajtov do 62 bajtov (áno, namiesto kompresie zväčšoval), a to aj pri trénovaní slovníkov (nedokázal som zistiť, ako prinútiť zstd, aby vytváral slovníky v trojbajtových krokoch; prezeral som slovník zstd a bol plný krátkych viet).

Existujú niektoré algoritmy na kompresiu krátkych textov, ako napríklad [shoco](https://ed-von-schleck.github.io/shoco/) a [smaz](https://github.com/antirez/smaz), ale tie fungujú len pre jazyky podobné angličtine a stále zosilňujú krátku čínštinu (ich slovníky majú len niekoľko stoviek znakov, čo je málo, takže ani preškolenie slovníkov nie je možné).

Ďalšou možnosťou kompresie je zmena kódovania textu.

Ak viete niečo o kódovaní unicode, pochopíte, že kódovacia schéma utf-8 vyžaduje tri bajty úložného priestoru pre jeden čínsky znak (čo je v skutočnosti dosť zbytočné).

V gb18030 zaberá jeden čínsky znak dva bajty, čím sa ušetrí 33 % miesta. Gb18030 však nepokrýva všetky znaky Unicode (je len podmnožinou utf8) a nemožno ho použiť.

Existujú štandardizované kompresné kódovania unicode, napríklad [scsu](https://github.com/dop251/scsu) (ktoré [používa SqlServer](https://docs.microsoft.com/en-us/sql/relational-databases/data-compression/unicode-compression-implementation?view=sql-server-ver15) ) a [utf-c](https://github.com/deNULL/utf-c).

[Testoval](https://denull.github.io/utf-c) som to a na jednu čínštinu pripadajú približne dva bajty plus jeden bajt navyše (napr. 4 čínštiny sú približne 2*4+1 = 9 bajtov).

![](https://raw.githubusercontent.com/gcxfd/img/gh-pages/ffxMd3.jpg)

Kľúčovou vecou je, že som hľadal na webe a nenašiel som žiadne implementácie rustu pre tieto dve kódovania.

Napísať vlastnú implementáciu týchto kódovaní v jazyku rust nie je nemožné, ale vyžaduje si to hlboké pochopenie intervalov kódovej tabuľky rôznych unikódových jazykov, čo je nákladné sa naučiť.

Tak som sa zamyslel, či by som nemohol vytvoriť všeobecnejšie a lepšie riešenie kódovania a kompresie.

Počet znakov v unicode je pevne stanovený a známy a schéma unicode-13.0.0 má 143859 znakov [(pozri tu)](https://github.com/rmw-link/utf8_compress/blob/master/all_char.py).

Je úplne možné spočítať frekvenciu výskytu každého znaku a potom ho komprimovať pomocou Hoffmanovho kódovania.

Použil som teda nejaký čínsky korpus a začal som počítať frekvenciu slov.

Korpus je nasledovný.

* [Čínsky korpus Wikipédie](https://jdhao.github.io/2019/01/10/two_chinese_corpus)
* [FictionDown web novel crawler](https://github.com/ma6254/FictionDown) (release verzia bude opakovane prehľadávať neplatné kapitoly, takže je potrebná master verzia `go get github.com/ma6254/FictionDown@master`)
* [Weibo crawler](https://github.com/gcxfd/weibo-crawler)
* [DHT crawler pre sieť BT](https://github.com/gcxfd/bt-spider)
* [Niekoľko crawlerov napísaných z ruky, pozri adresár s kódom pavúka](https://github.com/rmw-link/utf8_compress/tree/master/spider)

Výsledky sú dobré, tri čínske znaky sa dajú komprimovať na 5 bajtov, čo je už nad rámec kompresie gb18030.

Ďalej ma zaujímalo, či by som mohol do Hoffmanovho slovníka pridať bežné slová, aby som ešte viac optimalizoval účinok kompresie.

Vytvoril som teda slovník s bežne používanými slovami (komprimovaný na viac ako 500 KB) pomocou [tréningového algoritmu v adresári train](https://github.com/rmw-link/rmw-utf8/tree/master/train) pre separáciu slov + ngram.

Vyskúšal som ho a prekonáva všetky kompresné algoritmy na trhu.

Paráda.