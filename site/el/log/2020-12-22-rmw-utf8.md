# rmw-utf8 - κωδικοποίηση συμπίεσης utf8

Ένας σύντομος αλγόριθμος συμπίεσης κειμένου για utf-8, βελτιστοποιημένος για κινέζικα, βασισμένος στη γλώσσα προγραμματισμού rust.

Σημείωση: ο rmw-utf8 μπορεί να συμπιέσει μόνο κείμενο utf-8, δεν είναι αλγόριθμος συμπίεσης δυαδικών αρχείων γενικού σκοπού.

Υπάρχει μια [έκδοση rust](https://github.com/rmw-link/rmw-utf8) και μια [έκδοση wasm](https://github.com/rmw-lib/rmw-utf8-wasm) για javascript.

## Πώς να χρησιμοποιήσετε

```rust
use rmw_utf8::{decode, encode};

fn main() {
  let txt = "测试一下";
  let compressed = encode(&txt.as_bytes());
  let decompressed = decode(&compressed[..]);
  assert!(txt == decompressed);
}
```

## Αξιολόγηση ρυθμού συμπίεσης

Αυτός ο αλγόριθμος έχει σχεδιαστεί για τη συμπίεση σύντομων κειμένων και τα αποτελέσματα έχουν ως εξής. Όπως μπορείτε να δείτε, όσο πιο σύντομο είναι το κείμενο, τόσο καλύτερο είναι το ποσοστό συμπίεσης αυτού του αλγορίθμου.

Στα 22467 bytes (περίπου 7500 κινεζικοί χαρακτήρες), ο rmw-utf8 εξακολουθεί να υπερτερεί έναντι των γενικών αλγορίθμων συμπίεσης.

```
#include compress_test/test.txt
```

Το μηχάνημα δοκιμής είναι ένα MacBook Pro 2015 ( 2,2 GHz Intel Core i7 )

Ο κώδικας δοκιμής μπορεί να βρεθεί στο [compress_test](https://github.com/rmw-link/rmw-utf8/tree/master/compress_test)

## Σημειώσεις σχετικά με τη χρήση

Η συμπίεση αντικαθιστά τόσο το `\r\n` όσο και το `\r` στο κείμενο με το `\n`, πράγμα που σημαίνει ότι το συμπιεσμένο και το αποσυμπιεσμένο κείμενο μπορεί να μην είναι πανομοιότυπο.

### Ιστορία

Το `\r` είναι ένα carriage return και το `\n` είναι ένα line feed, το πρώτο φέρνει το δρομέα στην αρχή της γραμμής και το δεύτερο μετακινεί το δρομέα ένα πλαίσιο πιο κάτω.

Μια φορά κι έναν καιρό, πολύ πριν από τους υπολογιστές, υπήρχε ένα μηχάνημα που ονομαζόταν Teletype Model και μπορούσε να πληκτρολογήσει 10 χαρακτήρες ανά δευτερόλεπτο.

Το πρόβλημα ήταν ότι χρειαζόταν 0,2 δευτερόλεπτα για να γίνει ένα διάλειμμα γραμμής. Αν ένας νέος χαρακτήρας περνούσε μέσα σε αυτά τα 0,2 δευτερόλεπτα, ο χαρακτήρας θα χανόταν.

Έτσι, οι προγραμματιστές σκέφτηκαν να προσθέσουν δύο χαρακτήρες τέλους γραμμής σε κάθε γραμμή.

Η μία ονομάζεται "επιστροφή καροτσιού", η οποία λέει στη γραφομηχανή να τοποθετήσει την κεφαλή εκτύπωσης στο αριστερό όριο, και η άλλη ονομάζεται "τροφοδοσία γραμμής", η οποία λέει στη γραφομηχανή να μετακινήσει το χαρτί κατά μία γραμμή.

Από εδώ προέρχονται οι λέξεις "line feed" και "carriage return".

Αργότερα, όταν εφευρέθηκε ο ηλεκτρονικός υπολογιστής, οι δύο αυτές έννοιες εφαρμόστηκαν και στους υπολογιστές. Εκείνη την εποχή, η μνήμη ήταν πολύ ακριβή και ορισμένοι επιστήμονες θεώρησαν ότι ήταν μεγάλη σπατάλη να προσθέτουν δύο χαρακτήρες στο τέλος κάθε γραμμής, οπότε αρκούσε ένας.

Έτσι ο κόσμος άνοιξε.

Για τα συστήματα Unix/Linux, κάθε γραμμή τελειώνει με "line feed", δηλ. `\n`- για τα συστήματα Windows, η προεπιλογή είναι "carriage return + line feed", δηλ. - για τα συστήματα Mac, η προεπιλογή είναι "carriage return", δηλ. . `\r\n` - στα συστήματα Mac, η προεπιλογή είναι "carriage return", δηλαδή `\r`.

Οι σύγχρονοι επεξεργαστές κειμένου υποστηρίζουν πλέον το `\n` ως χαρακτήρα κλεισίματος, οπότε δεν υπάρχει ανάγκη ύπαρξης του `\r`.

## Εκπαίδευση προσαρμοσμένων λεξικών

Είναι δυνατό να εκπαιδεύσετε το δικό σας λεξικό συμπίεσης για διαφορετικές γλώσσες και τύπους κειμένου για να βελτιώσετε το αποτέλεσμα της συμπίεσης.

```bash
git clone --depth=1 https://github.com/rmw-link/rmw-utf8.git
cd rmw-utf8
# 在txt目录下放你的准备训练语料，格式为utf8编码的txt文件
cd train
./train.sh
```

## Συμπίεση ροής δεν έχει ακόμη εφαρμοστεί

Δεν έχει γίνει συμπίεση ροής (άλλωστε, το σενάριό μου αφορά κυρίως σύντομα κείμενα).

Όποιος το χρειάζεται μπορεί να συσκευάσει μια άλλη συμπίεση ροής από μόνος του.

Για παράδειγμα, συμπιέστε κάθε 1MB και, στη συνέχεια, καταγράψτε τον αριθμό των bytes του συμπιεσμένου περιεχομένου στην αρχή κάθε παραγράφου μετά τη συμπίεση.

## Αρχές κωδικοποίησης

Κείμενα από δώδεκα έως μερικές εκατοντάδες χαρακτήρες, κυρίως στα κινεζικά, δεν είναι κατάλληλα για αλγόριθμους συμπίεσης γενικής χρήσης.

Για παράδειγμα, δοκίμασα τον [zstd](https://github.com/facebook/zstd), τον πιο ισχυρό αλγόριθμο συμπίεσης στον κόσμο, και συχνά συμπίεζε 42 bytes σε 62 bytes (ναι, μεγέθυνε αντί να συμπιέζει), ακόμη και όταν εκπαίδευε λεξικά (δεν μπόρεσα να καταλάβω πώς να κάνω τον zstd να φτιάχνει λεξικά σε βήματα των 3 bytes- έκανα catting το λεξικό του zstd και ήταν γεμάτο από σύντομες προτάσεις).

Υπάρχουν ορισμένοι αλγόριθμοι συμπίεσης σύντομων κειμένων, όπως οι [shoco](https://ed-von-schleck.github.io/shoco/) και [smaz](https://github.com/antirez/smaz), αλλά αυτοί λειτουργούν μόνο για γλώσσες που μοιάζουν με τα αγγλικά και εξακολουθούν να ενισχύουν τα σύντομα κινεζικά (τα λεξικά τους έχουν μήκος μόνο μερικές εκατοντάδες χαρακτήρες, το οποίο δεν είναι αρκετό, οπότε ακόμη και η επανεκπαίδευση των λεξικών δεν είναι εφικτή).

Μια άλλη επιλογή συμπίεσης είναι η αλλαγή της κωδικοποίησης του κειμένου.

Αν γνωρίζετε οτιδήποτε για την κωδικοποίηση unicode, θα καταλάβετε ότι το σχήμα κωδικοποίησης utf-8 απαιτεί τρία bytes αποθηκευτικού χώρου για έναν κινεζικό χαρακτήρα (το οποίο στην πραγματικότητα είναι αρκετά σπάταλο).

Στο gb18030, ένας κινεζικός χαρακτήρας καταλαμβάνει δύο bytes, εξοικονομώντας το 33% του χώρου. Ωστόσο, το gb18030 δεν καλύπτει όλους τους χαρακτήρες unicode (είναι μόνο ένα υποσύνολο του utf8) και δεν μπορεί να χρησιμοποιηθεί.

Υπάρχουν τυποποιημένες κωδικοποιήσεις συμπίεσης unicode, όπως η [scsu](https://github.com/dop251/scsu)[(που χρησιμοποιείται από τον SqlServer](https://docs.microsoft.com/en-us/sql/relational-databases/data-compression/unicode-compression-implementation?view=sql-server-ver15) ) και η [utf-c](https://github.com/deNULL/utf-c).

Το [δοκίμασα](https://denull.github.io/utf-c) αυτό και είναι περίπου δύο bytes ανά κινέζικο, συν ένα επιπλέον byte (π.χ. 4 κινέζικα είναι περίπου 2*4+1 = 9 bytes).

![](https://raw.githubusercontent.com/gcxfd/img/gh-pages/ffxMd3.jpg)

Το βασικό είναι ότι έψαξα στο διαδίκτυο και δεν βρήκα καμία εφαρμογή σκουριάς για αυτές τις δύο κωδικοποιήσεις.

Το να γράψω τη δική μου υλοποίηση των κωδικοποιήσεων αυτών δεν είναι αδύνατο, αλλά απαιτεί μια βαθιά κατανόηση των διαστημάτων των πινάκων κώδικα των διαφόρων γλωσσών unicode, η οποία είναι δαπανηρή για να μάθω.

Αναρωτήθηκα λοιπόν αν θα μπορούσα να φτιάξω μια πιο γενική και καλύτερη λύση κωδικοποίησης και συμπίεσης.

Ο αριθμός των χαρακτήρων στο unicode είναι σταθερός και γνωστός, και το σχήμα unicode-13.0.0 έχει 143859 χαρακτήρες [(δείτε εδώ](https://github.com/rmw-link/utf8_compress/blob/master/all_char.py) ).

Είναι απολύτως δυνατό να μετρήσετε τη συχνότητα εμφάνισης κάθε χαρακτήρα και στη συνέχεια να τον συμπιέσετε χρησιμοποιώντας την κωδικοποίηση Hoffman.

Έτσι, χρησιμοποιώντας κάποιο κινεζικό σώμα κειμένων, άρχισα να μετράω τις συχνότητες των λέξεων.

Το σώμα έχει ως εξής.

* [Κινεζικό σώμα της Wikipedia](https://jdhao.github.io/2019/01/10/two_chinese_corpus)
* [FictionDown web novel crawler](https://github.com/ma6254/FictionDown) (η έκδοση έκδοσης θα ανιχνεύσει επανειλημμένα άκυρα κεφάλαια ξανά και ξανά, οπότε απαιτείται η κύρια έκδοση `go get github.com/ma6254/FictionDown@master`)
* [Weibo crawler](https://github.com/gcxfd/weibo-crawler)
* [DHT crawler για το δίκτυο BT](https://github.com/gcxfd/bt-spider)
* [Μερικά crawlers που γράφτηκαν αυθόρμητα, δείτε τον κατάλογο κώδικα αράχνης](https://github.com/rmw-link/utf8_compress/tree/master/spider)

Τα αποτελέσματα είναι καλά, τρεις κινεζικοί χαρακτήρες μπορούν να συμπιεστούν σε 5 bytes, που είναι ήδη πέρα από τη συμπίεση του gb18030.

Αναρωτήθηκα επίσης αν θα μπορούσα να προσθέσω κοινές λέξεις στο λεξικό του Hoffman για να βελτιστοποιήσω περαιτέρω το αποτέλεσμα της συμπίεσης.

Έτσι έφτιαξα ένα λεξικό με συχνά χρησιμοποιούμενες λέξεις (συμπιεσμένο σε πάνω από 500 KB) χρησιμοποιώντας [τον αλγόριθμο εκπαίδευσης στον κατάλογο train](https://github.com/rmw-link/rmw-utf8/tree/master/train) για διαχωρισμό λέξεων + ngram.

Το δοκίμασα και συντρίβει κάθε αλγόριθμο συμπίεσης που κυκλοφορεί στην αγορά.

Ωραία.